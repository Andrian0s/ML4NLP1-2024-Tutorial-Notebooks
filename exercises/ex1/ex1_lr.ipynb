{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Andrian0s/ML4NLP1-2024-Tutorial-Notebooks/blob/main/exercises/ex1/ex1_lr.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SwwQqWtxaMWs"
      },
      "source": [
        "# ML4NLP1\n",
        "\n",
        "## Starting Point for Exercise 1, part I\n",
        "\n",
        "This notebook is supposed to serve as a starting point and/or inspiration when starting exercise 1, part I.\n",
        "\n",
        "One of the goals of this exercise is to get you acquainted with sklearn and related libraries like pandas and numpy. You will probably need to consult the documentation of those libraries:\n",
        "- sklearn: [Documentation](https://scikit-learn.org/stable/user_guide.html)\n",
        "- Pandas: [Documentation](https://pandas.pydata.org/docs/#)\n",
        "- NumPy: [Documentation](https://numpy.org/doc/)\n",
        "- SHAP: [Documentation](https://shap.readthedocs.io/en/latest/index.html)\n",
        "\n",
        "## Task Description\n",
        "\n",
        "Follow the instructions in this notebook to:\n",
        "\n",
        "1. Explore the data and create training/test splits for your experiments\n",
        "\n",
        "2. Build a LogisticRegression classifier and design some relevant features to apply it to your data\n",
        "\n",
        "3. Conduct hyperparameter tuning to find the optimal hyperparameters for your model\n",
        "\n",
        "4. Explore your model's predictions and conduct an error analysis to see where the model fails\n",
        "\n",
        "5. Conduct an interpretability analysis, investigating the model's most important features.\n",
        "\n",
        "6. Conduct an ablation study using a subset of languages\n",
        "\n",
        "\n",
        "Throughout the notebook, there are questions that you should address in your report. These are marked with üóí‚ùì.\n",
        "\n",
        "‚òù Note, these questions are intended to provide you with an opportunity to reflect on what it is that you are doing and the kind of challenges you might face along the way.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kBqq-G2daMW7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Set seed for reproducibility\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading the datasets"
      ],
      "metadata": {
        "id": "fPqyEvoyURzd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hEqfrri6aMW8",
        "outputId": "7928e9d3-22e1-49e0-f738-bbb46de68046"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1QP6YuwdKFNUPpvhOaAcvv2Pcp4JMbIRs\n",
            "To: /content/x_train.txt\n",
            "100% 64.1M/64.1M [00:04<00:00, 15.8MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1QVo7PZAdiZKzifK8kwhEr_umosiDCUx6\n",
            "To: /content/x_test.txt\n",
            "100% 65.2M/65.2M [00:00<00:00, 205MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1QbBeKcmG2ZyAEFB3AKGTgSWQ1YEMn2jl\n",
            "To: /content/y_train.txt\n",
            "100% 480k/480k [00:00<00:00, 53.0MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1QaZj6bI7_78ymnN8IpSk4gVvg-C9fA6X\n",
            "To: /content/y_test.txt\n",
            "100% 480k/480k [00:00<00:00, 107MB/s]\n"
          ]
        }
      ],
      "source": [
        "#¬†Download dataset\n",
        "!gdown 1QP6YuwdKFNUPpvhOaAcvv2Pcp4JMbIRs #¬†x_train\n",
        "!gdown 1QVo7PZAdiZKzifK8kwhEr_umosiDCUx6 # x_test\n",
        "!gdown 1QbBeKcmG2ZyAEFB3AKGTgSWQ1YEMn2jl # y_train\n",
        "!gdown 1QaZj6bI7_78ymnN8IpSk4gVvg-C9fA6X #¬†y_test"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(f'x_train.txt') as f:\n",
        "    x_train = f.read().splitlines()\n",
        "with open(f'y_train.txt') as f:\n",
        "    y_train = f.read().splitlines()\n",
        "with open(f'x_test.txt') as f:\n",
        "    x_test = f.read().splitlines()\n",
        "with open(f'y_test.txt') as f:\n",
        "    y_test = f.read().splitlines()"
      ],
      "metadata": {
        "id": "oU9VZeEEabMQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n4PijB0TaMW8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "44e91634-aeac-4273-9a5a-e583dd4a6d13"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text label\n",
              "0  Klement Gottwaldi surnukeha palsameeriti ning ...   est\n",
              "1  Sebes, Joseph; Pereira Thomas (1961) (p√• eng)....   swe\n",
              "2  ‡§≠‡§æ‡§∞‡§§‡•Ä‡§Ø ‡§∏‡•ç‡§µ‡§æ‡§§‡§®‡•ç‡§§‡•ç‡§∞‡•ç‡§Ø ‡§Ü‡§®‡•ç‡§¶‡•ã‡§≤‡§® ‡§∞‡§æ‡§∑‡•ç‡§ü‡•ç‡§∞‡•Ä‡§Ø ‡§è‡§µ‡§Æ ‡§ï‡•ç‡§∑‡•á...   mai\n",
              "3  Apr√®s lo cort peri√≤de d'establiment a Basil√®a,...   oci\n",
              "4  ‡∏ñ‡∏ô‡∏ô‡πÄ‡∏à‡∏£‡∏¥‡∏ç‡∏Å‡∏£‡∏∏‡∏á (‡∏≠‡∏±‡∏Å‡∏©‡∏£‡πÇ‡∏£‡∏°‡∏±‡∏ô: Thanon Charoen Krung...   tha"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e793fcf4-7225-40cd-9cfd-6e221498d57d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Klement Gottwaldi surnukeha palsameeriti ning ...</td>\n",
              "      <td>est</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Sebes, Joseph; Pereira Thomas (1961) (p√• eng)....</td>\n",
              "      <td>swe</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>‡§≠‡§æ‡§∞‡§§‡•Ä‡§Ø ‡§∏‡•ç‡§µ‡§æ‡§§‡§®‡•ç‡§§‡•ç‡§∞‡•ç‡§Ø ‡§Ü‡§®‡•ç‡§¶‡•ã‡§≤‡§® ‡§∞‡§æ‡§∑‡•ç‡§ü‡•ç‡§∞‡•Ä‡§Ø ‡§è‡§µ‡§Æ ‡§ï‡•ç‡§∑‡•á...</td>\n",
              "      <td>mai</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Apr√®s lo cort peri√≤de d'establiment a Basil√®a,...</td>\n",
              "      <td>oci</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>‡∏ñ‡∏ô‡∏ô‡πÄ‡∏à‡∏£‡∏¥‡∏ç‡∏Å‡∏£‡∏∏‡∏á (‡∏≠‡∏±‡∏Å‡∏©‡∏£‡πÇ‡∏£‡∏°‡∏±‡∏ô: Thanon Charoen Krung...</td>\n",
              "      <td>tha</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e793fcf4-7225-40cd-9cfd-6e221498d57d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e793fcf4-7225-40cd-9cfd-6e221498d57d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e793fcf4-7225-40cd-9cfd-6e221498d57d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7e58c14d-5e91-40ee-a9ab-a85fb3be9c89\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7e58c14d-5e91-40ee-a9ab-a85fb3be9c89')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7e58c14d-5e91-40ee-a9ab-a85fb3be9c89 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_df"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "#¬†Combine x_train and y_train into one dataframe\n",
        "train_df = pd.DataFrame({'text': x_train, 'label': y_train})\n",
        "# Write train_df to csv with tab as separator\n",
        "train_df.to_csv('train_df.csv', index=False, sep='\\t')\n",
        "#¬†Comibne x_test and y_test into one dataframe\n",
        "test_df = pd.DataFrame({'text': x_test, 'label': y_test})\n",
        "# Inspect the first 5 items in the train split\n",
        "train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_96MFk6daMW9",
        "outputId": "3f1fa135-5b23-4225-82d3-af1de103a834"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['est', 'swe', 'mai', 'oci', 'tha', 'orm', 'lim', 'guj', 'pnb', 'zea', 'krc', 'hat', 'pcd', 'tam', 'vie', 'pan', 'szl', 'ckb', 'fur', 'wuu', 'arz', 'ton', 'eus', 'map-bms', 'glk', 'nld', 'bod', 'jpn', 'arg', 'srd', 'ext', 'sin', 'kur', 'che', 'tuk', 'pag', 'tur', 'als', 'koi', 'lat', 'urd', 'tat', 'bxr', 'ind', 'kir', 'zh-yue', 'dan', 'por', 'fra', 'ori', 'nob', 'jbo', 'kok', 'amh', 'khm', 'hbs', 'slv', 'bos', 'tet', 'zho', 'kor', 'sah', 'rup', 'ast', 'wol', 'bul', 'gla', 'msa', 'crh', 'lug', 'sun', 'bre', 'mon', 'nep', 'ibo', 'cdo', 'asm', 'grn', 'hin', 'mar', 'lin', 'ile', 'lmo', 'mya', 'ilo', 'csb', 'tyv', 'gle', 'nan', 'jam', 'scn', 'be-tarask', 'diq', 'cor', 'fao', 'mlg', 'yid', 'sme', 'spa', 'kbd', 'udm', 'isl', 'ksh', 'san', 'aze', 'nap', 'dsb', 'pam', 'cym', 'srp', 'stq', 'tel', 'swa', 'vls', 'mzn', 'bel', 'lad', 'ina', 'ava', 'lao', 'min', 'ita', 'nds-nl', 'oss', 'kab', 'pus', 'fin', 'snd', 'kaa', 'fas', 'cbk', 'cat', 'nci', 'mhr', 'roa-tara', 'frp', 'ron', 'new', 'bar', 'ltg', 'vro', 'lav', 'ces', 'yor', 'nso', 'bak', 'rus', 'ace', 'mdf', 'vep', 'sgs', 'uig', 'lit', 'sqi', 'som', 'slk', 'sco', 'ukr', 'mri', 'hrv', 'vol', 'eng', 'glv', 'ben', 'ido', 'jav', 'tcy', 'mrj', 'hif', 'sna', 'war', 'mlt', 'egl', 'tsn', 'lez', 'hak', 'kom', 'azb', 'que', 'lzh', 'ara', 'fry', 'dty', 'mal', 'heb', 'gag', 'chv', 'afr', 'pap', 'kin', 'ang', 'kaz', 'bjn', 'hye', 'olo', 'xmf', 'uzb', 'bcl', 'pdc', 'hsb', 'srn', 'kat', 'tgl', 'nno', 'glg', 'roh', 'kan', 'chr', 'lrc', 'div', 'myv', 'cos', 'hun', 'nrm', 'pfl', 'wln', 'bho', 'epo', 'deu', 'nav', 'mwl', 'pol', 'rue', 'vec', 'nds', 'aym', 'tgk', 'ceb', 'xho', 'bpy', 'ell', 'lij', 'hau', 'mkd', 'ltz']\n"
          ]
        }
      ],
      "source": [
        "# Get list of all labels\n",
        "labels = train_df['label'].unique().tolist()\n",
        "print(labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 1.1 Exploring the training data\n",
        "\n",
        "üìù‚ùìTake a look at a couple of texts from different languages and answer the following questions:\n",
        "\n",
        "1. Do you notice anything that might be challenging for the classification?\n",
        "2. How is the data distributed? (i.e., how many instances per label are there in the training and test set? Is it a balanced dataset?)\n",
        "3. Do you think the train/test split is appropriate (i.e., is the test data representative of the training data)? If not, please rearrange the data in a more appropriate way.\n"
      ],
      "metadata": {
        "id": "CSMKrNfm8Vzs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Inspect the training data"
      ],
      "metadata": {
        "id": "Dd2MQGaZ9EsZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2 Data preparation\n",
        "\n",
        "Get a subset of the train/test data that includes 20 languages.\n",
        "Include English, German, Dutch, Danish, Swedish, Norwegian, and Japanese, plus 13 additional languages of your choice based on the items in the list of labels."
      ],
      "metadata": {
        "id": "lz23kAYi8htB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Create your train/test subsets of languages\n"
      ],
      "metadata": {
        "id": "SghPjc0V9ECd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: With the following code, we wanted to ENCODE the labels, however, our cat was walking on the keyboard and some of it got changed. Can you fix it?\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "label_encoder = LabelEncoder().fit(y_train)\n",
        "y_train, y_test = label_encoder.fit(y_train), label_encoder.fit(y_test)\n",
        "print(label_encoder.classes_)\n",
        "print(y_train)\n",
        "print(y_test)"
      ],
      "metadata": {
        "id": "wmNmkFzsU_LS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1 Build a LogisticRegression classifier\n",
        "\n",
        "To start with, we're going to build a very simple LogisticRegression classifier.\n",
        "Use a `Pipeline` to chain togther a `CountVectorizer` and a `LogisticRegression` estimator. Then perform a 5-fold cross validation and report the scores of this model as a baseline."
      ],
      "metadata": {
        "id": "okK-6q5CW6tK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# TODO: Define a very basic pipeline using a CountVectorizer and a LogisticRegression classifier\n",
        "\n"
      ],
      "metadata": {
        "id": "p4HlptuhMgBh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Run a cross validation to estimate the model's expected performance"
      ],
      "metadata": {
        "id": "poIzePbjMrLc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 2.2 Feature Engineering\n",
        "\n",
        "So far, we've only considered the basic `CountVectorizer` at the word level to encode our input texts for our model.\n",
        "\n",
        "Your task is to apply some text preprocessing and engineer some more informative features.\n",
        "\n",
        "To do this, think about what other features might be relevant for determining the language of an input text.\n",
        "\n",
        "Define a custom set of feature extractors and implement the necessary preprocessing steps to extract these features from strings.\n",
        "\n",
        "Then initialise a processing pipeline that converts your input data into features that the model can take as input.\n",
        "\n",
        "‚òù Note, this step can be as involved as your heart desires, there is only one minimal requirement: you must use something more than the base `CountVectorizer`. We recommend that you take a look at the [`BaseEstimator`](https://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html) and [`TransformerMixin`](https://scikit-learn.org/stable/modules/generated/sklearn.base.TransformerMixin.html#transformermixin) classes from `sk-learn`, as these can be helpful for defining custom transformers.\n"
      ],
      "metadata": {
        "id": "cm7auSCoQ2mn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Data cleaning/Feature engineering steps"
      ],
      "metadata": {
        "id": "e6IJia5ge13b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "### 3.1 Grid Search\n",
        "\n",
        "Use sklearn's GridSearchCV and experiment with the following hyperparameters:\n",
        "1. Penalty (Regularization)\n",
        "2. Solver\n",
        "3. Experiment with parameters of the Vectorizer (optional, but highly advised)\n",
        "\n",
        "‚òù Note, don't overdo it at the beginning, since runtime might go up fast!\n",
        "\n",
        "Make sure you read through the [docs](https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html#logisticregression) to get an understanding of what these parameters do.\n"
      ],
      "metadata": {
        "id": "uFVupMHhfJN9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: GridSearchCV"
      ],
      "metadata": {
        "id": "M5s11IcneIU6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2 Best Model Selection\n",
        "\n",
        "After conducting our Grid Search, we should be able to identify our best model by inspecting the using the Grid Search result attribute `cv_results_`. (Hint: `cv_results_` returns a dictionay, so convert it to a Pandas Dataframe for easy inspection.)\n",
        "\n",
        "üìù‚ùì What were the hyperparameter combinations for your best-performing model on the test set.\n",
        "\n",
        "üìù‚ùì What is the advantage of grid search cross-validation?\n"
      ],
      "metadata": {
        "id": "TIxWwFC-Bcbe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Select the best model based on the GridSearch results"
      ],
      "metadata": {
        "id": "IH1q7v4heMP1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.3 Model Evaluation\n",
        "\n",
        "Once you have identified your best model, use it to predict the languages of texts in the test split.\n",
        "\n",
        "üìù‚ùì According to standard metrics (e.g. Accurracy, Precision, Recall and F1), how well does your model perform on the heldout test set?\n"
      ],
      "metadata": {
        "id": "uqGuryr5Pduw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Evaluate the model by inspecting the predictions on the heldout test set"
      ],
      "metadata": {
        "id": "I96IIw5IeSm9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "### 4.1 Error Analysis\n",
        "\n",
        "Inspect your model's predictions using a confusion matrix and provide a summary of what you find in your report.\n",
        "\n",
        "üìù‚ùì Where does your model do well and where does it fail?\n",
        "\n",
        "üìù‚ùì What are some possible reasons for why it fails in these cases?"
      ],
      "metadata": {
        "id": "nY7yivhIc31J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Inspect the model's predcitions on the different classes"
      ],
      "metadata": {
        "id": "Pvw_JReaeY__"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "### 5.1 Interpretability Analysis\n",
        "\n",
        "Now that you have your best model, it's time to dive deep into understanding how the model makes predictions.\n",
        "\n",
        "It is important that we can explain and visualise our models to improve task performance. Explainable models help characterise model fairness, transparency, and outcomes.\n",
        "\n",
        "Let's try to understand what our best-performing logistic regression classification model has learned.\n",
        "\n",
        "Inspect the 20 most important features for the languages English, Swedish, Norwegian, and Japanese. Please make sure that the features are named and human-interpretable, not things like \"Feat_1\". (Hint: if you have used custom feature extractors in your pipeline, you may need to adapt these to make sure that the feature names are maintained.)\n",
        "\n",
        "üìù‚ùì What is more important, extra features or the outputs of the vectorizer? Please discuss.\n",
        "\n",
        "We recommend using the [SHAP library](https://shap.readthedocs.io/en/latest/example_notebooks/tabular_examples/linear_models/Sentiment%20Analysis%20with%20Logistic%20Regression.html) as discussed in the tutorial. We've provided an example notebook for working with SHAP for multi-class classification in the course GitHub repo.\n",
        "\n",
        "‚òù Note, if you prefer to use another interpretability tool, we will accept answers from any explanation library/method as long as the explanations for the model weights are provided in a structured/clear way.\n",
        "\n"
      ],
      "metadata": {
        "id": "nLVGsAHENSKw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# To use shap, we first need to install it into the current environment\n",
        "!pip install --upgrade shap\n",
        "\n",
        "import shap"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QlXrrrBMR-2E",
        "outputId": "8ad2a6a9-fee9-418a-9d50-211a64237689"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: shap in /usr/local/lib/python3.10/dist-packages (0.46.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from shap) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from shap) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from shap) (1.5.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from shap) (2.1.4)\n",
            "Requirement already satisfied: tqdm>=4.27.0 in /usr/local/lib/python3.10/dist-packages (from shap) (4.66.5)\n",
            "Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.10/dist-packages (from shap) (24.1)\n",
            "Requirement already satisfied: slicer==0.0.8 in /usr/local/lib/python3.10/dist-packages (from shap) (0.0.8)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from shap) (0.60.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from shap) (2.2.1)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->shap) (0.43.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->shap) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->shap) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->shap) (2024.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->shap) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->shap) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->shap) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Inspect most important features according to the model using SHAP"
      ],
      "metadata": {
        "id": "yYiE9B7Nem1w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "### 6.1 Ablation Study\n",
        "\n",
        "Lastly, we want to conduct a small ablation study to investigate how well our model performs under different conditions.\n",
        "\n",
        "As a first step, choose the two languages for which the classifier worked best.\n",
        "\n",
        "Next, re-fit the best model six times, each time reducing the **length** of each instance in the training set. To do this, create a custom `TextReducer` class that you can include as a preprocessing step in your pipeline. The class should take a `max_len` argument as a hyperparameter that can be set to train the following models:\n",
        "\n",
        "- Model 1: `max_len = None` (i.e. no truncation!)\n",
        "- Model 2: `max_len = 500`\n",
        "- Model 3: `max_len = 250`\n",
        "- Model 4: `max_len = 150`\n",
        "- Model 5: `max_len = 100`\n",
        "- Model 6: `max_len = 50`\n",
        "\n",
        "Use average accuracy over the cross validation scores for each model to measure performance for each ablation setting.\n",
        "\n",
        "üìù‚ùì How does the reduction of training data affect the performance of the classifier? And what could be some possible reasons for this?"
      ],
      "metadata": {
        "id": "MZX8MCdvgQOJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Ablation study"
      ],
      "metadata": {
        "id": "jgegy9I_eBo9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "üìù‚ùì Write your lab report here addressing all questions in the notebook"
      ],
      "metadata": {
        "id": "FKEiEzVhc99J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "jWwX_ADfdAO0"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}